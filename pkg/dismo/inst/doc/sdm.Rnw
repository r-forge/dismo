\documentclass{article}

\usepackage{natbib}
\usepackage{graphics}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{hanging}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}

% \VignetteIndexEntry{Species distribution modeling with \R}
% \VignetteDepends{dismo}
% \VignetteKeyword{spatial}

% options(width=65)

\newcommand{\super}[1]{\ensuremath{^{\textrm{#1}}}}
\newcommand{\sub}[1]{\ensuremath{_{\textrm{#1}}}}
\newcommand{\R}{{\normalfont\textsf{R}}{}}

\SweaveOpts{keep.source=TRUE}

\begin{document}


\title{Species distribution modeling with \R}
\author{Robert J. Hijmans}
\maketitle


\section{Introduction}

This document is an introduction to species distribution modeling with \R. Species distribution modeling (SDM) is also known under other names including envelope-modeling and niche-modeling. In SDM, the following steps are usally taken: (1) locations of occurrence (and perhaps non-occurrence) of a species (or other phenomenon) are compiled. (2) Values from environmental predictor variables (such as climate) at these locations are determined. (3) The envrionmental values are used to fit a model predicting presence/absence, or another measure, such as abundance, associated with the points. (4) The model is used to predict the likelihood of presence at all locations of an area of interest (and perhaps in a future climate).

This document is not a general introduction to species distribution modeling itself. We assume that you are familiar with most of the concepts in this field. If in doubt, you could consult Richard Pearson's introduction to the subject: \url{http://biodiversityinformatics.amnh.org/index.php?section_id=111}. More advanced readers may want to consult the recent review of the field by Elith and Leathwick (2009).

We also assume that you are already familiar with the \R language and environment. It would be particularly useful if you already had some experience with statistical model fitting (e.g. the glm function) and with the '\verb@raster@' package.

SDM have been implemented in \R in many different ways. Here we focus on the functions in from the '\verb@dismo@' and the '\verb@raster@' packages (but we also refer to other packages such as '\verb@BIOMOD@)'. If you want to test, or build on, some of the examples presented here, make sure you have the latest versions of these libraries, and their dependencies, installed. If you are using a recent version of \R, you can do that with: 

\verb@install.packages(c('rJava', 'XML', 'sp', 'rgdal', 'raster'))@

\verb@install.packages("dismo", repos="http://R-Forge.R-project.org")@


\section{Occurence data}

Data preparation is often the most time consuming part of a species distribution modeling project. You need to collect a sufficient number of occurence records that document presence (and perhaps absence) of the species of you interest. A particularly important concern in species distribution modeling is whether, apart from the species identification, the coordinates of the location data are accurate enough (and whether uncertainty about the coordinates is known or not). You also need to have accurate and relevant spatial predictor variables at a sufficiently high spatial resolution. 

Importing occurrence data into \R is easy. But collecting, georeferencing, and cross-checking coordinate data is tedious. While we'll show you some useful data prepration steps you can do in \R, it is necessary to use additinal tools as well. Discussions about species distribution modeling often focus on comparing modeling methods, but if you are dealing with species with few and uncertain records, your focus probably ought to be on improving the quality of the occurence data. All methods do better if your occurence data is unbiased and free of error (Graham et al., 2007) and you have have a relatively large number of records (Wisz et al., 2008).


\subsection{Data import}

In most cases you will a file with point locality data representing the known distribution of a species. Here is an example of using \verb@read.table@ to read records that are stored in a text file. We are using a example file that is installed with the dismo package, and for that reason we use a complex way to construct the filename, but you can replace that with your own filename (remember to use forward slashes!)

<<sdm1>>=
library(dismo)
filename <- paste(system.file(package="dismo"), '/ex/bradypus.csv', sep='')
filename
bradypus <- read.table(filename, header=TRUE, sep=',')
head(bradypus)
@

You can also read such data directly out of Excel or from a database (see e.g. the \verb@RODBC@ package). No matter how you do it, the objective is to get a matrix (or a \verb@data.frame@) with at least 2 columns to hold the coordinates (typically longitude and latitude). In many cases you will have additional columns, e.g., a column to indicate the species if you are modeling multiple species; and a column to indicate whether this is a 'presence' or an 'absence' record (a much used convention is to code presence with a 1 and absence with a 0). 

If you do not have any species distribution data you can get started by downloading data from the Global Biodiversity Inventory Facility (GBIF) (\url{http://www.gbif.org/}). In the dismo package there is a function '\verb@gbif@' that you can use for this. The data used below were downloaded using the \texttt{gbif} function like this: 

\verb@acaule = gbif('solanum', 'acaule', geo=FALSE)@
\newline

Many records may not have coordinates. Out of the 699 records that gbif returned (March 2010), there were only 54 records with coordinates. 

<<sdm2>>=
data(acaule)
dim(acaule)
acgeo = subset(acaule, !is.na(lat) & !is.na(lon))
dim(acgeo)
acgeo[1:4, c(1:5,7:10)]
@

Here is a simple way to make a map of the occurrence localities of \textit{Solanum acaule}:

<<fig=TRUE, echo=TRUE>>=
library(maptools)
data(wrld_simpl)
plot(wrld_simpl, xlim=c(-130,10), ylim=c(-60,60))
points(acgeo$lon, acgeo$lat, col='red')
@


\subsection{Cross-checking}

\textit{Solanum acaule} is a species that occurs in the higher parts of the Andes mountains of Peru and Bolivia. Do you see any errors on the map? There are three records that have plausible latitudes, but longitudes of zero, which is clearly wrong, as this puts them in the Atlantic Ocean, south of West Africa. The gbif function (with default arguments) removes records that have (0, 0) as coordinates, but not if one of the coordinates is zero. 

Let's have a look at these records:
<<sdm3>>=
lonzero = subset(acaule, lon==0)
lonzero[, 1:13]
@

The records are from Bolivia (BOL), Peru (PER) and Argentina (ARG), confirming that coordinates are in error (it could have been that the coordinates were correct for a location in the Ocean, perhaps referring to a location a fish was caught rather than a place where S. acaule was collected). Interestingly, another data quality issue is revealed: each record occurs twice. This could happen because plant samples are often split and send to multiple herbariums. But in this case it seems that a single GBIF data provider (IPK) has these record duplicated in its database. 

It is important to cross-check coordinates by visual and other means. One approach is to compare the country (and lower level administrative subdivisions) of the site as specified by the records, with the country implied by the coordinates (Hijmans et al., 1999). In the example below we use the 'coordinates' function from the '\verb@sp@' package to create a SpatialPointsDataFrame, and then the 'overlay' function, also from '\verb@sp@', to do a point-in-polygon query with the countries polygons.

<<sdm4>>=
library(sp)
coordinates(acgeo) = ~lon+lat
ov = overlay(acgeo, wrld_simpl)
cntr = as.character(wrld_simpl@data$NAME[ov])
which(is.na(cntr))
i = which(cntr != acgeo@data$country)
cbind(cntr, acgeo@data$country)[i,]
@

Note that the polygons that we used in the example above are not very precise, and they should not be used in a real analysis (see \url{http://www.gadm.org/} for more detailed administrative division files, or use the '\verb@getData@' function from the raster package (e.g. \texttt{getData('gadm', country='PER', level=0)} to get the national borders of Peru. The overlay function returned indices (row numbers) that we stored in variable '\verb@i@'. We used these in the next line to get the country for each point. Then we ask which countries are '\verb@NA@' (i.e., points in oceans), and which countries have non matching names (in this case these are all caused by using abbreviations in stead of full names).

<<sdm4b>>=
acgeo  = acgeo[coordinates(acgeo)[,'lon'] < 0, ]
@

\subsection{Georeferencing}

If you have records with locality descriptions but no coordinates, you should consider georeferencing these. Not all the records can be georeferenced. Sometimes even the country is unknown (country=="UNK"). Here we select only records that do not have coordinates, but that do have a locality description.

<<sdm5>>=
georef = subset(acaule, (is.na(lon) | is.na(lat)) & ! is.na(locality) )
dim(georef)
georef[1:3,1:13]
@

Among the first records is an old acquaintance. The record, with catalog number WKS 30048 was also in the set of records that had a longitude of zero degrees. This time it seems that it is served to gbif via another institution 'DEU' (I suspect that these duplicates occur because GBIF has records from aggregators such as EURISCO and national nodes, as well as from individual institutes). 

We recommend using a tool like BioGeomancer: \url{http://bg.berkeley.edu/latest} (Guralnick et al., 2006) to georeference textual locality descriptions. An important feature of BioGeomancer is that it attempts to capture the uncertainty associated with each georeference (Wieczorek et al., 2004). The dismo package has a function \texttt{biogeomancer} that you can use for this, and that we demonstrate below, but its use is generally not recommended because you really need a detailed map interface for accurate georeferencing. 

Here is an example for one of the records with longitude = 0

<<sdm6>>=
args(biogeomancer)
b = biogeomancer('Peru', locality=lonzero$locality[3], progress='')
b
lonzero$lat[3]
@

Note that the uncertainty (expressed in meters) is quite high, and that the latitude is rather different from the original latitude (whereas the original latitude might in fact be correct). 


\section{Background (random absence) data}

Many of the early species distribution models, such as Bioclim and Domain are known as 'profile' methods because they only use 'presence' data. Other methods also use 'absence' data or 'background' data. Logistic regression is the classical approach to analyzing presence and absence data (and it is still much used, often implemented in a generalized linear modeling (GLM) framework; and the 'maxent' algorithm is also closely related to logistic regression). If you have a large dataset with presence/absence from a well designed survey, you should use a method that can use these data (i.e. do not use a modeling method that only considers presence data). If you only have presence data, you can still use a method that needs absence data, by substiting absence data with background data. 

Background data, also referred to as 'random absence' is, in many cases, not \textit{that} different from 'true absence' data. If you have a species with a  range that is relatively small compared to they study area, there will only a few background points where the species is actually present. Moreover, the species might be absent (not observable) at these sites at a given time of sampling (depending on scale, detectability, ...). In fact, if you are modeling at, say, a 1 km\super{2} resolution, all species that are present within a grid cell will also be absent somewhere within that cell. Background data establishes the environmental domain of the study, presence data should establish under which conditions a species is more likely to be present than on average. 'True' absence data can be less noisy, and help detect more subtle interactions in variables that determine distribution and/or biogeographic barriers. However, absence data can also be biased and incomplete and in such cases probably less useful than presence data.

dismo has a function to sample random points (background data) from a study area. You can use a 'mask' to exclude area with no data \texttt{NA}, e.g. areas not on land. You can use an 'extent' to further restrict the area from which random locations are drawn.

<<fig=TRUE , echo=TRUE>>=
files <- list.files(path=paste(system.file(package="dismo"), '/ex', sep=''),
                    pattern='grd', full.names=TRUE )
mask <- raster(files[[1]])
bg <- randomPoints(mask, 500 )
par(mfrow=c(1,2))
plot(!is.na(mask), legend=FALSE)
points(bg, cex=0.5)
# now with an extent
e = extent(-80, -53, -39, -22)
bg2 <- randomPoints(mask, 50, ext=e)
plot(!is.na(mask), legend=FALSE)
plot(e, add=TRUE, col='red')
points(bg2, cex=0.5)
@

\section{Predictor variables}

In species distribution modeling, predictor variables are typically organized as raster (grid) type files. Each predictor should be a 'raster' representing a variable of interest. Variables can include climatic, soil and terrain, vegetation, land use, and other variables. These data are typically stored in files in some kind of GIS format. Almost all relevant formats can be used (including ESRI grid, geoTiff, netCDF, IDRISI, and ASCII). Avoid ASCII files if you can, as they tend to considerably slow down processing speed. For any particular study the layers all should have the same spatial extent, resolution, and origin (if necessary, see the '\texttt{raster}' package to prepare your predictor variable data). The set of predictor variables (raster) can be used to make a '\texttt{RasterStack}', which can be thought of as a collection of '\texttt{RasterLayer}' objects(see the \texttt{raster} package for more info). 

<<sdm9>>=
files <- list.files(path=paste(system.file(package="dismo"), '/ex', sep=''),
                    pattern='grd', full.names=TRUE )
files
predictors <- stack(files)
layerNames(predictors)

<<sdm10, fig=TRUE, echo=TRUE>>=
plot(predictors)
@

<<sdm11, fig=TRUE, echo=TRUE>>=
plot(predictors, 1)
plot(wrld_simpl, add=TRUE)
points(bradypus[,2:3], col='red', cex=0.5)
points(acgeo, col='blue', pch='x', cex=0.5)
@

The example above uses data representing 'bioclimatic variables' from the WorldClim database (\url{http://www.worldclim.org}, Hijmans et al., 2004) and 'terrestiral biome' data from the WWF
(\url{http://www.worldwildlife.org/science/data/item1875.html}, Olsen et al., 2001). You can go to these websites if you want higher resolution data. You can also use the \texttt{getData} function from the \texttt{raster} package to download WorldClim climate data (as well as other geographic data).

Variable selection is obviously important, particularly of the objective of a study is explanation. See, e.g., Austin and Smith (1987), Austin (2002). In SDM, the objective tends to be prediction, in which case variable selection might be less important (as long as there are enough variables with different spatial patterns); but this is an area that needs further research. 


\section{Extracting values from rasters}

We now have a set of predictor variables (rasters) and occurence points. The next step is to extract the values of the predictors at the locations of the points. (This step can be skipped for the modeling methods that are implemented in the dismo package). This is very straightfoward thing to do using the xyValues function from the raster package. In the example below we use that function first for the \textit{Bradypus} occurence points, then for 500 random background points. We combine these into a single \texttt{data.frame} in which the first column (variable 'pb') indicates whether this is a presence or a background point. 'biome' is catagorical variable (called a 'factor' in \R) and it is important to explicitly define it that way (so that it won't be treated like any other numerical variable).

<<sdm12, echo=TRUE>>=
presvals <- xyValues(predictors, bradypus[,2:3])
backgr <- randomPoints(predictors, 500)
absvals <- xyValues(predictors, backgr)
pb <- c(rep(1, nrow(presvals)), rep(0, nrow(absvals)))
sdmdata <- data.frame(cbind(pb, rbind(presvals, absvals)))
sdmdata[,'biome'] = as.factor(sdmdata[,'biome'])
head(sdmdata)
tail(sdmdata)
summary(sdmdata)
pairs(sdmdata[,2:5], cex=0.1, fig=TRUE)
@

\section{Model fitting}

Model fitting is quite similar accross the modeling methods that exist in \R. Most methods take a '\texttt{formula}' identifying the dependent and independent variables, accompanied with a \texttt{data.frame} that holds these variables. 

A simple formula could look like: \texttt{y ~ x1 + x2 + x3}, i.e. y is a function of x1, x2, and x3. Another example is \texttt{y ~ .}, which means that y is a function of all other variables in the \texttt{data.frame} provided to the function. See \texttt{help('formula')} for more details about the formula syntax. In the example below, the function '\texttt{glm}' is used to fit generalized linear models. \texttt{glm} returns a model object.
<<sdm13, echo=TRUE>>=
m1 = glm(pb ~ bio1 + bio5 + bio12, data=sdmdata)
class(m1)
summary(m1)

m2 = glm(pb ~ ., data=sdmdata)
m2
@

Models implemented in dismo do not use a formula (and most models only take presence points). For example:

<<sdm13b, echo=TRUE, fig=TRUE>>=
bc = bioclim(sdmdata[,c('bio1', 'bio5', 'bio12')])
bc
pairs(bc)
@


\section{Model predictions}

Different modeling methods return differt type of 'model' objects (typically they have the same name as the modeling method used). All of these 'model' objects, irrespective of their exact class, can be used to with the \texttt{predict} function to make predictions for any combination of values of the independent variables. This is illusrated in the example below where we make predictions with model object 'm1' for three records with values for variables bio1, bio5 and bio12 (the variables used in the example above to create object m1)

<<sdm14, echo=TRUE>>=
bio1 = c(40, 150, 200)
bio5 = c(60, 115, 290)
bio12 = c(600, 1600, 1700)
pd = data.frame(cbind(bio1, bio5, bio12))
pd
predict(m1, pd)
predict(bc, pd)
@



\section{Model evaluation}

Traditional measures of fit used in regression, such as r\super{2} and textit{p}-values have little place in species distribution modeling. For some methods these metrics do not apply. But even if they do, they should normally not be used as all the classic assumptions on which they are based (independence of data, normality of distributions) are typically strongly violated. In stead, most modelers rely on cross-validation. This consists of creating a model with one 'training' data set, and testing it with another data set of known occurences. Typically, training and testing data are created through random sampling (without replacement) from a single data set. Only in a few cases, e.g. Elith et al., 2006, training and test data are from different sources and pre-defined.

Different measures can be used to evaluate the quality of a prediction (Fielding and Bell, 1997), perhaps depending on the goal of the study. Many measueres are 'threshold dependent'. That means that a threshold must be set first (e.g. 0.5). Predicted values above that threshold indicate a prediction of 'presence', and values below the threshold indicate 'absence'. Some measures emphasize the weight of false absences, others give more weight to false presences. Cohen's \textit{kappa} is an example of a threshold dependent model evaluation statistic.

Much used statistics that are threshold independent are the correlation coefficient and the Area Under the Receiver Operator Curve (AUROC, generally further abbreviated to AUC). AUC is a measure of rank-correlation. If it is high, it indicates that high predicted scores tend to be areas of known presence and locations with lower model prediction scores tend to areas where the species is known to be absent (or a random point). An AUC score of 0.5 means that the model is as good as a random guess.

We illustrate the computation of the correlation coefficient, AUC with two random variables. p (presence) represents the predicted value for 50 known cases (locations) where the species is present. and a (absence) represents the predicted value for 50 known cases (locations) where the species is absent. First create and explore the two random variables:

<<sdm15, echo=TRUE, fig=TRUE>>=
p = rnorm(50, mean=0.7, sd=0.3)
a = rnorm(50, mean=0.4, sd=0.4)
par(mfrow=c(1, 2))
plot(sort(p), col='red', pch=21)
points(sort(a), col='blue', pch=24)
legend(1, 0.9 * max(a,p), c('presence', 'absence'), pch=c(21,24), col=c('red', 'blue'))

comb = c(p,a)
group = c(rep('presence', length(p)), rep('absence', length(a)))
boxplot(comb~group, col=c('blue', 'red'))
@

The two variables clearly have different distributions, and the values for 'presence' tend to be higher than for 'absence'. Below we compute the correlation coeficient and the AUC:

<<sdm16, echo=TRUE>>=
group = c(rep(1, length(p)), rep(0, length(a))) 
cor.test(comb, group)
mv <- wilcox.test(p,a)
auc <- as.numeric(mv$statistic) / (length(p) * length(a))
auc
@

The dismo package makes computing these, and other, statistics easier:

<<sdm17, echo=TRUE, fig=TRUE>>=
e = evaluate(p=p, a=a)
class(e)
e
par(mfrow=c(1, 2))
plot(e, 'kappa')
plot(e, 'ROC')
@

<<sdm18, echo=TRUE, fig=TRUE>>=
par(mfrow=c(1, 2))
density(e)
boxplot(e)
@

The ROCR package has similar functionality.

Now back to some real, presence-only, data. We'll divide the data in two random sets, one for training, one for testing.

<<sdm19, echo=TRUE>>=
rand <- round(0.75 * runif(nrow(sdmdata)))
traindata <- sdmdata[rand==0,]
traindata <- traindata[traindata[,1] == 1, 2:9]
testdata <- sdmdata[rand==1,]
bc <- bioclim(traindata)
e <- evaluate(testdata[testdata==1,], testdata[testdata==0,], bc)
e
@


\subsection{k-fold partitioning}

<<sdm20, echo=TRUE>>=
k <- 5
occ <- sdmdata[sdmdata[,1] == 1, 2:9]
abs  <- sdmdata[sdmdata[,1] == 0, 2:9]
fold <- kfold(occ, k)
e <- list()
for (i in 1:k) {
	train <- occ[fold != i,]
	test <- occ[fold == i,]
	bc <- bioclim(train)
	e[[i]] <- evaluate(p=test, a=abs, bc)
}	

auc = sapply(e, function(x)slot(x, 'auc'))
auc
mean(auc)
@


\section{Dealing with uncertainty}





\section{Model transfer in space and time}





\section{Model averaging}



\section{Modeling methods}

profile, regression, machine learning



\section{Profile methods}

The three methods described here are all implemented in the dismo package.

\subsection{Bioclim}

The BIOCLIM algorithm has been extensively used for species distribution modeling. BIOCLIM is a classic 'climate-envelope-model'. Although it generally does not perform as good as some other modeling methods (Elith et al. 2006, Hijmans and Graham, 2006), it is still used, among other reasons because the algorithm is easy to understand and thus useful in teaching species distribution modeling. The BIOCLIM algorithm computes the similarity of a location by comparing the values of environmental variables at any location to a percentile distribution of the values at known locations of occurence ('training sites'). The closer to the 50th percentile (the median), the more suitable the location is. The tails of the distribution are not distinguished, that is, 10 percentile is treated as equivalent to 90 percentile. In this implementation in R, the values of the upper tail values are transformed to the lower tail, and the minimum percentile score across all the environmental variables is used (i.e. BIOCLIM using an approach like Liebig's law of the minimum). This value is substracted from 1 and then mutlipled with two so that the results are between 0 and 1. The reason for scaling this way is that the results become more like that of other distributon modeling methods and are thus easier to interpret. The value 1 will rarely be observed as it would require a location that has the median value of the training data for all the variables considered. The value 0 is very common as it is assinged to all cells with a value of an environmental variable that is outside the percentile distribution (the range of the training data) for at least one of the variables.


\subsection{Domain}

The Domain algorithm (Carpenter et al. 1993) that has been extensively used for species distribution modeling. It did not perform very well in a model comparison (Elith et al. 2006) and very poorly when assessing climate change effects (Hijmans and Graham, 2006). The Domain algorithm computes the Gower distance between environmental variables at any location and those at any of the known locations of occurence ('training sites'). 


The distance between the environment at point A and those of the known occurences for a single climate variable is calculated as
the absolute difference in the values of that variable divided by the range of the variable across all known occurence points (i.e., the distance is scaled by the range of observations). For each variable the minimum distance beteen a site and any of the training points is taken. The Gower distance is then the mean of these distances over all environmental variables. The Domain algorithm assigns to a place the distance to the closest known occurence (in environmental space). 


To integrate over environmental variables, the distance to any of the variables is used. This distance is substracted from one, and (in this R implementation) values below zero are truncated so that the scores are between 0 (low) and 1 (high).



\subsection{Mahalanobis}

The \texttt{mahal} function implements a species distribution model based on the Mahalanobis distance (Mahalanobis, 1936). Mahalanobis distance takes into account the correlations of the variables in the data set, and it is not dependent on the scale of measurements.


\section{Regression models}

\subsection{Generalized Linear Models}

\subsection{Generalized Additive Models}



\section{Machine learning methods}

There is a variety of machine learning (sometimes referred to data mining) methods in R. For a long time there have been packages to do Artifical Neural Networks (ANN) and Classification and Regressin Trees (CART). More recent methods include Random Forests, Boosted Regression Trees, and Support Vector Machines. Through the dismo package you can also use the Maxent program, that implements the most widely used method (maxent) in species distribution modeling. 

\subsection{Maxent}
The maxent (Maximum Entropy) species distribution model (see references below). The function uses presence and 'background' data for a number of locations, and the values of a number of predictors (independent variables) for those locations. The result is a predictive model that can be used to predict the suitability of other locations, for example to predict the entire range of a species, or its potential range in another region, or under changed conditions. 

The way Maxent is implemented in dismo is a bit different from other methods. This function uses the maxent species distribution model software, which is a java program that you can download from \url{http://www.cs.princeton.edu/~schapire/maxent/}. Put the file 'maxent.jar' in the 'java' folder of this package. That is the folder returned by \texttt{system.file("java", package="dismo")}. Please note that this program (\texttt{maxent.jar}) can not be redistributed or used for commercial purposes. 



\subsection{Boosted Regression Trees}

Boosted Regression Trees (BRT) is, unfortunately, known by a large number of different names. It was developed by Friedman (2001), who referred to it as a "Gradient Boosting Machine" (GBM). It is also known as "Gradient Boost", "Stochastic Gradient Boosting", "Gradient Tree Boosting". The method is implemented in the '\texttt{gbm}' package in \R. 

The article by Elith, Leathwick and Hastie (2009) describes the use of BRT in the context of species distribution modeling. Their article is accompanied by a number of R functions and a tutorial. The functions have been slightly adjusted and incorporated into the 'dismo' package. These funcitons extend the funcitons in the '\texttt{gbm}' package, with the goal to make these easier to apply to ecological data, and to enhance interpretation.  The adapted tutorial is available as a vignette to the dismo package. You can access it via the index of the help pages, or with this command: \texttt{vignette('gbm', 'dismo')}


\subsection{Random Forest}

library(randomForest)
m1 = randomForest(data[,c('bio1', 'bio5', 'bio12')], sdmdata[,'bio1'])


\subsection{Support Vector Machines}



\subsection{Other methods}

Neural networks


\section{Multi-species models}

\subsection{mars}

\subsection{gdm}




\section{Geographic models}

The 'geographic models' described here are not commonly used in species distribution modeling. They are an attempt to formalize methods to draw 'expert range maps'. They can also be interpreted as null-models.

\section{Geographic models (presence-only)}

\subsection{Distance}

\subsection{Convex hulls}

\subsection{Circles}


\section{Geographic models (presence-absence)}

\subsection{Inverse distance}

\subsection{Voronoi hulls}



\section{Mechanistic models}



\section{References}
\begin{hangparas}{3em}{1}


\noindent Austin MP, 2002. Spatial prediction of species distribution: an interface between ecological theory and statistical modelling. Ecological Modelling 157:101-18.

\noindent Austin, M.P., and T.M. Smith, 1989. A new model for the continuum concept. Vegetatio 83:35-47.

\noindent Breiman, L., 2001. Statistical Modeling: The Two Cultures. Statistical Science 16: 199-215.

\noindent Carpenter G., A.N. Gillison and J. Winter, 1993. Domain: a flexible modelling procedure for  mapping potential distributions of plants and animals. Biodiversity Conservation 2:667-680.

\noindent Elith, J., C.H. Graham, R.P. Anderson, M. Dudik, S. Ferrier, A. Guisan, R.J. Hijmans, F. Huettmann, J. Leathwick, A. Lehmann, J. Li, L.G. Lohmann, B. Loiselle, G. Manion, C. Moritz, M. Nakamura, Y. Nakazawa, J. McC. Overton, A.T. Peterson, S. Phillips, K. Richardson, R. Scachetti-Pereira, R. Schapire, J. Soberon, S. Williams, M. Wisz and N. Zimmerman, 2006. Novel methods improve prediction of species' distributions from occurrence data. Ecography 29: 129-151. \url{http://dx.doi.org/10.1111/j.2006.0906-7590.04596.x}

\noindent Elith, J. and J.R. Leathwick, 2009. Species Distribution Models: Ecological Explanation and Prediction Across Space and Time. Annual 
Review of Ecology, Evolution, and Systematics 40: 677-697. \url{http://dx.doi.org/10.1146/annurev.ecolsys.110308.120159}

\noindent Elith, J., J.R. Leathwick and T. Hastie, 2009. A working guide to boosted regression trees. Journal of Animal Ecology 77: 802-81

\noindent Ferrier, S. and A. Guisan, 2006. Spatial modelling of biodiversity at the community level. Journal of Applied Ecology 43:393-40

\noindent Fielding, A.H. and J.F. Bell, 1997. A review of methods for the assessment of prediction errors in conservation presence/absence models. Environmental Conservation 24: 38-49

\noindent Friedman, J.H., 2001. Greedy function approximation: a gradient boosting machine. The Annals of Statistics 29: 1189-1232. \url{http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf)}

\noindent Graham, C.H., J. Elith, R.J. Hijmans, A. Guisan, A.T. Peterson, B.A. Loiselle and the NCEAS Predicting Species Distributions Working Group, 2007. The influence of spatial errors in species occurrence data used in distribution models. Journal of Applied Ecology 45: 239-247 

\noindent Guisan, A., Thomas C. Edwards, Jr, and Trevor Hastie, 2002. Generalized linear and generalized additive models in studies of species distributions: setting the scene. Ecological Modelling 157: 89-100.

\noindent Guralnick, R.P., J. Wieczorek, R. Beaman, R.J. Hijmans and the BioGeomancer Working Group, 2006. BioGeomancer:  Automated georeferencing to map the world's biodiversity data. PLoS Biology 4: 1908-1909. \url{http://dx.doi.org/10.1371/journal.pbio.0040381}

\noindent Hastie, T., R. Tibshirani and J. Friedman, 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Second Edition) \url{http://www-stat.stanford.edu/~tibs/ElemStatLearn/}

\noindent Hijmans R.J., and C.H. Graham, 2006. Testing the ability of climate envelope models to predict the effect of climate change on species distributions. Global change biology 12: 2272-2281. \url{http://dx.doi.org/10.1111/j.1365-2486.2006.01256.x}

\noindent Hijmans, R.J., M. Schreuder, J. de la Cruz and L. Guarino, 1999. Using GIS to check coordinates of germplasm accessions. Genetic Resources and Crop Evolution 46: 291-296.

\noindent Hijmans, R.J., S.E. Cameron, J.L. Parra, P.G. Jones and A. Jarvis, 2005. Very high resolution interpolated climate surfaces for global land areas. International Journal of Climatology 25: 1965-1978. \url{http://dx.doi.org/10.1002/joc.1276}

\noindent Mahalanobis, P.C., 1936. On the generalised distance in statistics. Proceedings of the National Institute of Sciences of India 2: 49-55.

\noindent Nix, H.A., 1986. A biogeographic analysis of Australian elapid snakes. In: Atlas of Elapid Snakes of Australia. (Ed.) R. Longmore, pp. 4-15. Australian Flora and Fauna Series Number 7. Australian Government Publishing Service: Canberra.

\noindent Olson, D.M, E. Dinerstein, E.D. Wikramanayake, N.D. Burgess, G.V.N. Powell, E.C. Underwood, J.A. D'amico, I. Itoua, H.E. Strand, J.C. Morrison, C.J. Loucks, T.F. Allnutt, T.H. Ricketts, Y. Kura, J.F. Lamoreux, W.W.Wettengel, P. Hedao, and K.R. Kassem. 2001. Terrestrial Ecoregions of the World: A New Map of Life on Earth. BioScience 51:933-938

\noindent Phillips, S.J., R.P. Anderson, R.E. Schapire, 2006. Maximum entropy modeling of species geographic distributions. Ecological Modelling 190: 231-259.

\noindent Wieczorek, J., Q. Guo and R.J. Hijmans, 2004. The point-radius method for georeferencing point localities and calculating associated uncertainty. International Journal of Geographic Information Science 18: 745-767.

\noindent Wisz, M.S., R.J. Hijmans, J. Li, A.T. Peterson, C.H. Graham, A. Guisan, and the NCEAS Predicting Species Distributions Working Group, 2008. Effects of sample size on the performance of species distribution models. Diversity and Distributions 14: 763-773. 


\end{hangparas}



\end{document}

