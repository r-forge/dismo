\documentclass{article}

\usepackage{natbib}
\usepackage{graphics}
\usepackage{amsmath}
\usepackage{indentfirst}
\usepackage{hanging}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}

% \VignetteIndexEntry{Species distribution modeling with \R}
% \VignetteDepends{dismo}
% \VignetteKeyword{spatial}

<<echo=false>>=
options(width=60)
@

\newcommand{\super}[1]{\ensuremath{^{\textrm{#1}}}}
\newcommand{\sub}[1]{\ensuremath{_{\textrm{#1}}}}
\newcommand{\R}{{\normalfont\textsf{R}}{}}

\SweaveOpts{keep.source=TRUE}

\begin{document}


\title{Species distribution modeling with \R}
\author{Robert J. Hijmans}
\maketitle


\section{Introduction}

This document is an introduction to species distribution modeling with \R. Species distribution modeling (SDM) is also known under other names including envelope-modeling and niche-modeling. In SDM, the following steps are usally taken: (1) locations of occurrence (and perhaps non-occurrence) of a species (or other phenomenon) are compiled. (2) Values from environmental predictor variables (such as climate) at these locations are determined. (3) The envrionmental values are used to fit a model predicting presence/absence, or another measure, such as abundance, associated with the points. (4) The model is used to predict the likelihood of presence at all locations of an area of interest (and perhaps in a future climate).

This document is not a general introduction to species distribution modeling itself. We assume that you are familiar with most of the concepts in this field. If in doubt, you could consult Richard Pearson's introduction to the subject: \url{http://biodiversityinformatics.amnh.org/index.php?section_id=111}. More advanced readers may want to consult the recent review of the field by Elith and Leathwick (2009).

We also assume that you are already familiar with the \R language and environment. It would be particularly useful if you already had some experience with statistical model fitting (e.g. the glm function) and with the '\verb@raster@' package.

SDM have been implemented in \R in many different ways. Here we focus on the functions in from the '\verb@dismo@' and the '\verb@raster@' packages (but we also refer to other packages such as '\verb@BIOMOD@)'. If you want to test, or build on, some of the examples presented here, make sure you have the latest versions of these libraries, and their dependencies, installed. If you are using a recent version of \R, you can do that with: 

\verb@install.packages(c('rJava', 'XML', 'sp', 'rgdal', 'raster'))@

\verb@install.packages("dismo", repos="http://R-Forge.R-project.org")@


\section{Occurence data}

Data preparation is often the most time consuming part of a species distribution modeling project. You need to collect a sufficient number of occurence records that document presence (and perhaps absence) of the species of you interest. A particularly important concern in species distribution modeling is whether, apart from the species identification, the coordinates of the location data are accurate enough (and whether uncertainty about the coordinates is known or not). You also need to have accurate and relevant spatial predictor variables at a sufficiently high spatial resolution. 

Importing occurrence data into \R is easy. But collecting, georeferencing, and cross-checking coordinate data is tedious. While we'll show you some useful data prepration steps you can do in \R, it is necessary to use additinal tools as well. Discussions about species distribution modeling often focus on comparing modeling methods, but if you are dealing with species with few and uncertain records, your focus probably ought to be on improving the quality of the occurence data. All methods do better if your occurence data is unbiased and free of error (Graham et al., 2007) and you have have a relatively large number of records (Wisz et al., 2008).


\subsection{Data import}

In most cases you will a file with point locality data representing the known distribution of a species. Here is an example of using \verb@read.table@ to read records that are stored in a text file. We are using a example file that is installed with the dismo package, and for that reason we use a complex way to construct the filename, but you can replace that with your own filename (remember to use forward slashes!)

<<sdm1>>=
library(dismo)
filename <- paste(system.file(package="dismo"), '/ex/bradypus.csv', sep='')
filename
occurrence <- read.table(filename, header=TRUE, sep=',')
head(occurrence)
@

You can also read such data directly out of Excel or from a database (see e.g. the \verb@RODBC@ package). No matter how you do it, the objective is to get a matrix (or a \verb@data.frame@) with at least 2 columns to hold the coordinates (typically longitude and latitude). In many cases you will have additional columns, e.g., a column to indicate the species if you are modeling multiple species; and a column to indicate whether this is a 'presence' or an 'absence' record (a much used convention is to code presence with a 1 and absence with a 0). 

If you do not have any species distribution data you can get started by downloading data from the Global Biodiversity Inventory Facility (GBIF) (\url{http://www.gbif.org/}). In the dismo package there is a function '\verb@gbif@' that you can use for this. The data used below were downloaded using the \texttt{gbif} function like this: 

\verb@acaule = gbif('solanum', 'acaule', geo=FALSE)@
\newline

Many records may not have coordinates. Out of the 699 records that gbif returned (March 2010), there were only 54 records with coordinates. 

<<sdm2>>=
data(acaule)
dim(acaule)
acgeo = subset(acaule, !is.na(lat) & !is.na(lon))
dim(acgeo)
acgeo[1:4, c(1:5,7:10)]
@

Here is a simple way to make a map of the occurrence localities of \textit{Solanum acaule}:

<<fig=TRUE, echo=TRUE>>=
library(maptools)
data(wrld_simpl)
plot(wrld_simpl, xlim=c(-130,10), ylim=c(-60,60))
points(acgeo$lon, acgeo$lat, col='red')
@


\subsection{Cross-checking}

\textit{Solanum acaule} is a species that occurs in the higher parts of the Andes mountains of Peru and Bolivia. Do you see any errors on the map? There are three records that have plausible latitudes, but longitudes of zero, which is clearly wrong, as this puts them in the Atlantic Ocean, south of West Africa. The gbif function (with default arguments) removes records that have (0, 0) as coordinates, but not if one of the coordinates is zero. 

Let's have a look at these records:
<<sdm3>>=
lonzero = subset(acaule, lon==0)
lonzero[, 1:13]
@

The records are from Bolivia (BOL), Peru (PER) and Argentina (ARG), confirming that coordinates are in error (it could have been that the coordinates were correct for a location in the Ocean, perhaps referring to a location a fish was caught rather than a place where S. acaule was collected). Interestingly, another data quality issue is revealed: each record occurs twice. This could happen because plant samples are often split and send to multiple herbariums. But in this case it seems that a single GBIF data provider (IPK) has these record duplicated in its database. 

It is important to cross-check coordinates by visual and other means. One approach is to compare the country (and lower level administrative subdivisions) of the site as specified by the records, with the country implied by the coordinates (Hijmans et al., 1999). In the example below we use the 'coordinates' function from the '\verb@sp@' package to create a SpatialPointsDataFrame, and then the 'overlay' function, also from '\verb@sp@', to do a point-in-polygon query with the countries polygons.

<<sdm4>>=
library(sp)
coordinates(acgeo) = ~lon+lat
ov = overlay(acgeo, wrld_simpl)
cntr = as.character(wrld_simpl@data$NAME[ov])
which(is.na(cntr))
i = which(cntr != acgeo@data$country)
cbind(cntr, acgeo@data$country)[i,]
@

Note that the polygons that we used in the example above are not very precise, and they should not be used in a real analysis (see \url{http://www.gadm.org/} for more detailed administrative division files, or use the '\verb@getData@' function from the raster package (e.g. \texttt{getData('gadm', country='PER', level=0)} to get the national borders of Peru. The overlay function returned indices (row numbers) that we stored in variable '\verb@i@'. We used these in the next line to get the country for each point. Then we ask which countries are '\verb@NA@' (i.e., points in oceans), and which countries have non matching names (in this case these are all caused by using abbreviations in stead of full names).

<<sdm4b>>=
acgeo  = acgeo[coordinates(acgeo)[,'lon'] < 0, ]
@

\subsection{Georeferencing}

If you have records with locality descriptions but no coordinates, you should consider georeferencing these. Not all the records can be georeferenced. Sometimes even the country is unknown (country=="UNK"). Here we select only records that do not have coordinates, but that do have a locality description.

<<sdm5>>=
georef = subset(acaule, (is.na(lon) | is.na(lat)) & ! is.na(locality) )
dim(georef)
georef[1:3,1:13]
@

Among the first records is an old acquaintance. The record, with catalog number WKS 30048 was also in the set of records that had a longitude of zero degrees. This time it seems that it is served to gbif via another institution 'DEU' (I suspect that these duplicates occur because GBIF has records from aggregators such as EURISCO and national nodes, as well as from individual institutes). 

We recommend using a tool like BioGeomancer: \url{http://bg.berkeley.edu/latest} (Guralnick et al., 2006) to georeference textual locality descriptions. An important feature of BioGeomancer is that it attempts to capture the uncertainty associated with each georeference (Wieczorek et al., 2004). The dismo package has a function \texttt{biogeomancer} that you can use for this, and that we demonstrate below, but its use is generally not recommended because you really need a detailed map interface for accurate georeferencing. 

Here is an example for one of the records with longitude = 0

<<sdm6>>=
args(biogeomancer)
b = biogeomancer('Peru', locality=lonzero$locality[3], progress='')
b
lonzero$lat[3]
@

Note that the uncertainty (expressed in meters) is quite high, and that the latitude is rather different from the original latitude (whereas the original latitude might in fact be correct). 


\section{Background (random absence) data}

Many of the early species distribution models, such as Bioclim and Domain are known as 'profile' methods because they only use 'presence' data. Other methods also use 'absence' data or 'background' data. Logistic regression is the classical approach to analyzing presence and absence data (and it is still much used, often implemented in a generalized linear modeling (GLM) framework; and the 'maxent' algorithm is also closely related to logistic regression). If you have a large dataset with presence/absence from a well designed survey, you should use a method that can use these data (i.e. do not use a modeling method that only considers presence data). If you only have presence data, you can still use a method that needs absence data, by substiting absence data with background data. 

Background data, also referred to as 'random absence' is, in many cases, not \textit{that} different from 'true absence' data. If you have a species with a  range that is relatively small compared to they study area, there will only a few background points where the species is actually present. Moreover, the species might be absent (not observable) at these sites at a given time of sampling (depending on scale, detectability, ...). In fact, if you are modeling at, say, a 1 km\super{2} resolution, all species that are present within a grid cell will also be absent somewhere within that cell. Background data establishes the environmental domain of the study, presence data should establish under which conditions a species is more likely to be present than on average. 'True' absence data can be less noisy, and help detect more subtle interactions in variables that determine distribution and/or biogeographic barriers. However, absence data can also be biased and incomplete and in such cases probably less useful than presence data.

dismo has a function to sample random points (background data) from a study area. You can use a 'mask' to exclude area with no data \texttt{NA}, e.g. areas not on land. You can use an 'extent' to further restrict the area from which random locations are drawn.

<<fig=TRUE , echo=TRUE>>=
files <- list.files(path=paste(system.file(package="dismo"), '/ex', sep=''),
                    pattern='grd', full.names=TRUE )
mask <- raster(files[[1]])
bg <- randomPoints(mask, 500 )
par(mfrow=c(1,2))
plot(!is.na(mask), legend=FALSE)
points(bg, cex=0.5)
# now with an extent
e = extent(-80, -53, -39, -22)
bg2 <- randomPoints(mask, 50, ext=e)
plot(!is.na(mask), legend=FALSE)
plot(e, add=TRUE, col='red')
points(bg2, cex=0.5)
@

\section{Predictor variables}

In species distribution modeling, predictor variables are typically organized as raster (grid) type files. Each predictor should be a 'raster' representing a variable of interest. Variables can include climatic, soil and terrain, vegetation, land use, and other variables. These data are typically stored in files in some kind of GIS format. Almost all relevant formats can be used (including ESRI grid, geoTiff, netCDF, IDRISI, and ASCII). Avoid ASCII files if you can, as they tend to considerably slow down processing speed. For any particular study the layers all should have the same spatial extent, resolution, and origin (if necessary, see the '\texttt{raster}' package to prepare your predictor variable data). The set of predictor variables (raster) can be used to make a '\texttt{RasterStack}', which can be thought of as a collection of '\texttt{RasterLayer}' objects(see the \texttt{raster} package for more info). 

<<sdm9>>=
files <- list.files(path=paste(system.file(package="dismo"), '/ex', sep=''),
                    pattern='grd', full.names=TRUE )
files
predictors <- stack(files)
layerNames(predictors)

<<sdm10, fig=TRUE, echo=TRUE>>=
plot(predictors)
@

<<sdm11, fig=TRUE, echo=TRUE>>=
plot(predictors, 1)
plot(wrld_simpl, add=TRUE)
points(occurrence[,2:3], col='red', cex=0.5)
points(acgeo, col='blue', pch='x', cex=0.5)
@

The example above uses data representing 'bioclimatic variables' from the WorldClim database (\url{http://www.worldclim.org}, Hijmans et al., 2004) and 'terrestiral biome' data from the WWF
(\url{http://www.worldwildlife.org/science/data/item1875.html}, Olsen et al., 2001). You can go to these websites if you want higher resolution data. You can also use the \texttt{getData} function from the \texttt{raster} package to download WorldClim climate data (as well as other geographic data).


\section{Model fitting}

Model fitting is almost the same for all of the modeling methods that exist in \R. You either provide a formula identifying the dependent and independent variables, or you provide these as a vector and matrix (data.frame).

A simple formula could look like: 

y ~ x1 + x2





\section{Model predictions}






\section{Model evaluation}

Model evaluation typically consists of creating model training and a model testing data sets through random sampling (in some cases, e.g. Elith et al., 2006, training and test data are from different sources and pre-defined).


\subsection{k-fold partitioning}




\section{Dealing with uncertainty}





\section{Model transfer in space and time}





\section{Model averaging}




\section{Profile methods}

The three methods described here are all implemented in the dismo package.

\subsection{Bioclim}

\subsection{Domain}

\subsection{Mahalanobis}


\section{Regression models}

\subsection{Generalized Linear Models}

\subsection{Generalized Additive Models}



\section{Machine learning methods}

There is a variety of machine learning (sometimes referred to data mining) methods in R. For a long time there have been packages to do Artifical Neural Networks (ANN) and Classification and Regressin Trees (CART). More recent methods include Random Forests, Boosted Regression Trees, and Support Vector Machines. Through the dismo package you can also use the Maxent program, that implements the most widely used method (maxent) in species distribution modeling. 

\subsection{Maxent}

The way Maxent is implemented is a bit different from other methods. It depends on an external library that you need to download and put in the 'java' folder of the dismo package. See ?maxent


\subsection{Boosted Regression Trees}

See the dedicated vignette.


\subsection{Random Forest}


\subsection{Support Vector Machines}


\subsection{Other methods}

Neural networks


\section{Multi-species models}

\subsection{mars}

\subsection{gdm}



\section{Geographic models}

The 'geographic models' described here are not commonly used in species distribution modeling. They are an attempt to formalize methods to draw 'expert range maps'. They can also be interpreted as null-models.

\section{Geographic models (presence-only)}

\subsection{Distance}

\subsection{Convex hulls}

\subsection{Circles}


\section{Geographic models (presence-absence)}

\subsection{Inverse distance}

\subsection{Voronoi hulls}




\section{References}
\begin{hangparas}{3em}{1}

\noindent Elith, J., C.H. Graham, R.P. Anderson, M. Dudik, S. Ferrier, A. Guisan, R.J. Hijmans, F. Huettmann, J. Leathwick, A. Lehmann, J. Li, L.G. Lohmann, B. Loiselle, G. Manion, C. Moritz, M. Nakamura, Y. Nakazawa, J. McC. Overton, A.T. Peterson, S. Phillips, K. Richardson, R. Scachetti-Pereira, R. Schapire, J. Soberon, S. Williams, M. Wisz and N. Zimmerman, 2006. Novel methods improve prediction of species' distributions from occurrence data. Ecography 29: 129-151. \url{http://dx.doi.org/10.1111/j.2006.0906-7590.04596.x}

\noindent Elith, J. and J.R. Leathwick, 2009. Species Distribution Models: Ecological Explanation and Prediction Across Space and Time. Annual Review of Ecology, Evolution, and Systematics 40: 677-697. \url{http://dx.doi.org/10.1146/annurev.ecolsys.110308.120159}

\noindent Fielding, A.H. and J.F. Bell, 1997. A review of methods for the assessment of prediction errors in conservation presence/absence models. Environmental Conservation 24: 38-49

\noindent Graham, C.H., J. Elith, R.J. Hijmans, A. Guisan, A.T. Peterson, B.A. Loiselle and the NCEAS Predicting Species Distributions Working Group, 2007. The influence of spatial errors in species occurrence data used in distribution models. Journal of Applied Ecology 45: 239-247 

\noindent Guralnick, R.P., J. Wieczorek, R. Beaman, R.J. Hijmans and the BioGeomancer Working Group, 2006. BioGeomancer:  Automated georeferencing to map the world's biodiversity data. PLoS Biology 4: 1908-1909. \url{http://dx.doi.org/10.1371/journal.pbio.0040381}

\noindent Hijmans, R.J., M. Schreuder, J. de la Cruz and L. Guarino, 1999. Using GIS to check coordinates of germplasm accessions. Genetic Resources and Crop Evolution 46: 291-296.

\noindent Hijmans, R.J., S.E. Cameron, J.L. Parra, P.G. Jones and A. Jarvis, 2005. Very high resolution interpolated climate surfaces for global land areas. International Journal of Climatology 25: 1965-1978. \url{http://dx.doi.org/10.1002/joc.1276}

\noindent Olson, D.M, E. Dinerstein, E.D. Wikramanayake, N.D. Burgess, G.V.N. Powell, E.C. Underwood, J.A. D'amico, I. Itoua, H.E. Strand, J.C. Morrison, C.J. Loucks, T.F. Allnutt, T.H. Ricketts, Y. Kura, J.F. Lamoreux, W.W.Wettengel, P. Hedao, and K.R. Kassem. 2001. Terrestrial Ecoregions of the World: A New Map of Life on Earth. BioScience 51:933-938

\noindent Phillips, S.J., R.P. Anderson, R.E. Schapire, 2006. Maximum entropy modeling of species geographic distributions. Ecological Modelling 190: 231-259.

\noindent Wieczorek, J., Q. Guo and R.J. Hijmans, 2004. The point-radius method for georeferencing point localities and calculating associated uncertainty. International Journal of Geographic Information Science 18: 745-767.

\noindent Wisz, M.S., R.J. Hijmans, J. Li, A.T. Peterson, C.H. Graham, A. Guisan, and the NCEAS Predicting Species Distributions Working Group, 2008. Effects of sample size on the performance of species distribution models. Diversity and Distributions 14: 763-773. 


\end{hangparas}


\end{document}

